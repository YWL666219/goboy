import json
import streamlit as st, sqlite3, hashlib, time, pandas as pd, json
from datetime import datetime
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents import AgentType


# è®°å¿†ç®¡ç†ç±»
class ConversationMemory:
    def __init__(self, db_path="conversation_memory.db"):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT, session_id TEXT, question TEXT, 
            answer TEXT, question_hash TEXT, data_hash TEXT, timestamp DATETIME, response_time REAL)""")
        
        cursor.execute("""CREATE TABLE IF NOT EXISTS quick_answers (
            id INTEGER PRIMARY KEY AUTOINCREMENT, question_hash TEXT UNIQUE, data_hash TEXT, 
            question TEXT, answer TEXT, hit_count INTEGER DEFAULT 1, last_used DATETIME, created_at DATETIME)""")
        
        conn.commit()
        conn.close()

    def get_question_hash(self, question: str) -> str:
        return hashlib.md5(question.lower().strip().encode('utf-8')).hexdigest()

    def get_data_hash(self, df) -> str:
        try:
            data_str = str(df.shape) + str(df.columns.tolist()) + str(df.dtypes.tolist())
            return hashlib.md5(data_str.encode('utf-8')).hexdigest()
        except:
            return "unknown"

    def add_conversation(self, session_id: str, question: str, answer: str, data_hash: str, response_time: float):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        question_hash = self.get_question_hash(question)
        cursor.execute("""INSERT INTO conversations (session_id, question, answer, question_hash, data_hash, timestamp, response_time)
                       VALUES (?, ?, ?, ?, ?, ?, ?)""", (session_id, question, answer, question_hash, data_hash, datetime.now(), response_time))
        conn.commit()
        conn.close()

    def get_quick_answer(self, question: str, data_hash: str) -> Dict[str, Any]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        question_hash = self.get_question_hash(question)
        cursor.execute("SELECT answer, hit_count FROM quick_answers WHERE question_hash = ? AND data_hash = ?", (question_hash, data_hash))
        result = cursor.fetchone()
        if result:
            cursor.execute("UPDATE quick_answers SET hit_count = hit_count + 1, last_used = ? WHERE question_hash = ? AND data_hash = ?", 
                          (datetime.now(), question_hash, data_hash))
            conn.commit()
            conn.close()
            return {"found": True, "answer": result[0], "hit_count": result[1] + 1}
        conn.close()
        return {"found": False}

    def save_quick_answer(self, question: str, answer: str, data_hash: str):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        question_hash = self.get_question_hash(question)
        cursor.execute("INSERT OR REPLACE INTO quick_answers (question_hash, data_hash, question, answer, hit_count, last_used, created_at) VALUES (?, ?, ?, ?, 1, ?, ?)", 
                      (question_hash, data_hash, question, answer, datetime.now(), datetime.now()))
        conn.commit()
        conn.close()

    def get_conversation_history(self, session_id: str, limit: int = 10) -> List[Dict]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT question, answer, timestamp, response_time FROM conversations WHERE session_id = ? ORDER BY timestamp DESC LIMIT ?", (session_id, limit))
        results = cursor.fetchall()
        conn.close()
        return [{"question": row[0], "answer": row[1], "timestamp": row[2], "response_time": row[3]} for row in reversed(results)]

    def get_popular_questions(self, data_hash: str, limit: int = 5) -> List[Dict]:
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT question, hit_count, last_used FROM quick_answers WHERE data_hash = ? ORDER BY hit_count DESC LIMIT ?", (data_hash, limit))
        results = cursor.fetchall()
        conn.close()
        return [{"question": row[0], "hit_count": row[1], "last_used": row[2]} for row in results]


# å…¨å±€è®°å¿†ç®¡ç†å™¨å®ä¾‹
memory_manager = ConversationMemory()

PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚è¯·ä½¿ç”¨python_repl_astå·¥å…·æ‰§è¡Œpandasä»£ç åˆ†ææ•°æ®ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›æœ€ç»ˆç»“æœï¼š

**åˆ†ææ­¥éª¤ï¼š**
1. ç†è§£ç”¨æˆ·é—®é¢˜
2. ç¼–å†™pandasä»£ç è¿›è¡Œåˆ†æ
3. å°†ç»“æœæ ¼å¼åŒ–ä¸ºæŒ‡å®šçš„JSONæ ¼å¼

**è¿”å›æ ¼å¼è¦æ±‚ï¼š**
- çº¯æ–‡å­—å›ç­”ï¼š{"answer": "ç®€æ´çš„å›ç­”å†…å®¹"}
- è¡¨æ ¼æ•°æ®ï¼š{"table":{"columns":["åˆ—å1", "åˆ—å2"], "data":[["å€¼1", "å€¼2"], ["å€¼3", "å€¼4"]]}}
- æŸ±çŠ¶å›¾ï¼š{"bar":{"columns": ["ç±»åˆ«1", "ç±»åˆ«2"], "data":[æ•°å€¼1, æ•°å€¼2]}}
- æŠ˜çº¿å›¾ï¼š{"line":{"columns": ["æ—¶é—´1", "æ—¶é—´2"], "data": [æ•°å€¼1, æ•°å€¼2]}}

**é‡è¦è§„åˆ™ï¼š**
- ä½¿ç”¨python_repl_astå·¥å…·æ‰§è¡Œpandasä»£ç 
- å­—ç¬¦ä¸²å¿…é¡»ç”¨åŒå¼•å·ï¼Œæ•°å€¼ä¸åŠ å¼•å·
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œæ— è¯­æ³•é”™è¯¯
- æœ€ç»ˆå¿…é¡»è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ç»“æœ

ç”¨æˆ·é—®é¢˜ï¼š\n"""


@st.cache_data(ttl=1800)  # ç¼“å­˜30åˆ†é’Ÿ
def cached_dataframe_analysis(df_hash, query_hash, query):
    """ç¼“å­˜æ•°æ®åˆ†æç»“æœ"""
    # å®é™…çš„åˆ†æé€»è¾‘ä¼šåœ¨dataframe_agentä¸­æ‰§è¡Œ
    return None

load_dotenv()
def get_enhanced_model(model_choice="gpt-4.1-mini"):
    """è·å–å¢å¼ºçš„AIæ¨¡å‹"""
    model_configs = {
        "gpt-4o": {
            "model": "gpt-4o",
            "temperature": 0.1,
            "max_tokens": 8192
        },
        "gpt-4o-mini": {
            "model": "gpt-4o-mini",
            "temperature": 0,
            "max_tokens": 4096
        },
        "gpt-4-turbo": {
            "model": "gpt-4-turbo-preview",
            "temperature": 0.2,
            "max_tokens": 8192
        }
    }

    config = model_configs.get(model_choice, model_configs["gpt-4o-mini"])

    return ChatOpenAI(
        base_url='https://twapi.openai-hk.com/v1',
        #api_key=st.secrets['API_KEY'],
        **config
    )


def dataframe_agent(df, query, model_choice="gpt-4o-mini", use_cache=True, session_id=None):
    """æ•°æ®åˆ†ææ™ºèƒ½ä½“"""
    start_time = time.time()
    data_hash = memory_manager.get_data_hash(df)

    # æ£€æŸ¥ç¼“å­˜
    if use_cache:
        quick_answer = memory_manager.get_quick_answer(query, data_hash)
        if quick_answer["found"]:
            try:
                cached_result = json.loads(quick_answer["answer"])
                if session_id:
                    memory_manager.add_conversation(session_id, query, quick_answer["answer"], data_hash, time.time() - start_time)
                return cached_result
            except json.JSONDecodeError:
                pass

    # åˆ›å»ºæ™ºèƒ½ä½“
    try:
        model = get_enhanced_model(model_choice)
        agent = create_pandas_dataframe_agent(llm=model, df=df, verbose=False, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, allow_dangerous_code=True, return_intermediate_steps=False)
    except Exception as e:
        return {"answer": "AIæ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"}

    # æ„å»ºæç¤ºè¯
    enhanced_prompt = PROMPT_TEMPLATE + f"""
æ•°æ®é›†ä¿¡æ¯ï¼šè¡Œæ•°{len(df)}ï¼Œåˆ—æ•°{len(df.columns)}ï¼Œåˆ—å{', '.join(df.columns.tolist())}ï¼Œæ•°å€¼åˆ—{', '.join(df.select_dtypes(include=['number']).columns.tolist())}ï¼Œæ–‡æœ¬åˆ—{', '.join(df.select_dtypes(include=['object']).columns.tolist())}
ç”¨æˆ·é—®é¢˜ï¼š{query}"""

    try:
        response = agent.invoke({"input": enhanced_prompt})
        if "output" not in response or not response["output"]:
            return {"answer": "AIåˆ†æå¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•"}
        
        output = response["output"].strip()
        try:
            result = json.loads(output)
        except json.JSONDecodeError:
            import re
            json_match = re.search(r'\{.*\}', output, re.DOTALL)
            if json_match:
                try:
                    result = json.loads(json_match.group())
                except json.JSONDecodeError:
                    return {"answer": f"åˆ†æå®Œæˆï¼Œä½†ç»“æœæ ¼å¼æœ‰è¯¯ï¼š{output[:100]}..."}
            else:
                return {"answer": f"åˆ†æç»“æœï¼š{output[:100]}..."}
        
        if not isinstance(result, dict):
            return {"answer": "åˆ†æå®Œæˆï¼Œä½†è¿”å›æ ¼å¼ä¸æ­£ç¡®"}

        response_time = time.time() - start_time
        result_json = json.dumps(result, ensure_ascii=False)
        
        if session_id:
            memory_manager.add_conversation(session_id, query, result_json, data_hash, response_time)
        
        if "answer" in result or "table" in result or "bar" in result or "line" in result:
            memory_manager.save_quick_answer(query, result_json, data_hash)
        
        return result

    except Exception as err:
        error_result = {"answer": "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·é‡æ–°å°è¯•"}
        if session_id:
            memory_manager.add_conversation(session_id, query, json.dumps(error_result, ensure_ascii=False), data_hash, time.time() - start_time)
        return error_result





# è®°å¿†ç®¡ç†è¾…åŠ©å‡½æ•°
def get_session_id():
    if "session_id" not in st.session_state:
        st.session_state.session_id = f"session_{int(time.time())}_{hash(str(time.time()))}"
    return st.session_state.session_id

def display_conversation_history(df, limit=5):
    history = memory_manager.get_conversation_history(get_session_id(), limit)
    if history:
        for i, conv in enumerate(history):
            question_preview = conv['question'][:50] + "..." if len(conv['question']) > 50 else conv['question']
            st.markdown(f"**ğŸ’¬ é—®é¢˜ {i + 1}:** {question_preview}")
            with st.container():
                st.markdown(f"**å®Œæ•´é—®é¢˜:** {conv['question']}")
                try:
                    answer_data = json.loads(conv['answer'])
                    if "answer" in answer_data:
                        st.markdown(f"**å›ç­”:** {answer_data['answer']}")
                    if "table" in answer_data:
                        st.markdown("**æ•°æ®è¡¨æ ¼:**")
                        result_df = pd.DataFrame(answer_data["table"]["data"], columns=answer_data["table"]["columns"])
                        st.dataframe(result_df, use_container_width=True)
                except:
                    st.markdown(f"**å›ç­”:** {conv['answer']}")
                st.caption(f"â±ï¸ å“åº”æ—¶é—´: {conv['response_time']:.2f}ç§’ | ğŸ• æ—¶é—´: {conv['timestamp']}")
                st.divider()
    else:
        st.info("æš‚æ— å¯¹è¯å†å²")

def display_popular_questions(df, limit=5):
    popular = memory_manager.get_popular_questions(memory_manager.get_data_hash(df), limit)
    if popular:
        for i, item in enumerate(popular):
            col1, col2 = st.columns([4, 1])
            with col1:
                if st.button(f"ğŸ“ {item['question']}", key=f"popular_{i}"):
                    st.session_state.selected_question = item['question']
                    st.rerun()
            with col2:
                st.caption(f"ğŸ”¥ {item['hit_count']}æ¬¡")
    else:
        st.info("æš‚æ— çƒ­é—¨é—®é¢˜")


def get_memory_stats(df):
    session_id = get_session_id()
    data_hash = memory_manager.get_data_hash(df)
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) FROM conversations WHERE session_id = ?", (session_id,))
    session_count = cursor.fetchone()[0]
    cursor.execute("SELECT COUNT(*) FROM quick_answers WHERE data_hash = ?", (data_hash,))
    quick_answers_count = cursor.fetchone()[0]
    cursor.execute("SELECT COUNT(*) FROM conversations")
    total_conversations = cursor.fetchone()[0]
    cursor.execute("SELECT AVG(response_time) FROM conversations WHERE data_hash = ?", (data_hash,))
    avg_response_time = cursor.fetchone()[0] or 0
    
    conn.close()
    return {"session_count": session_count, "quick_answers_count": quick_answers_count, 
            "total_conversations": total_conversations, "avg_response_time": avg_response_time}

def clear_session_memory(session_id):
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    cursor.execute("DELETE FROM conversations WHERE session_id = ?", (session_id,))
    deleted_count = cursor.rowcount
    conn.commit()
    conn.close()
    return deleted_count

def clear_all_memory():
    conn = sqlite3.connect(memory_manager.db_path)
    cursor = conn.cursor()
    cursor.execute("DELETE FROM conversations")
    cursor.execute("DELETE FROM quick_answers")
    conn.commit()
    conn.close()
    return True